{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Prerequisites\n",
    "Install Theano and Lasagne using the following commands:\n",
    "\n",
    "```bash\n",
    "pip install -r https://raw.githubusercontent.com/Lasagne/Lasagne/master/requirements.txt\n",
    "pip install https://github.com/Lasagne/Lasagne/archive/master.zip\n",
    "```\n",
    "\n",
    "Working in a virtual environment is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data preparation\n",
    "\n",
    "Current code allows to generate geodesic patches from a collection of shapes represented as triangular meshes.\n",
    "To get started with the pre-processing:\n",
    "```\n",
    "git clone https://github.com/jonathanmasci/ShapeNet_data_preparation_toolbox.git\n",
    "```\n",
    "\n",
    "The usual processing pipeline is show in ```run_forrest_run.m```. \n",
    "We will soon update this preparation stage, so perhaps better to start with our pre-computed dataset, and stay tuned! :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepared data\n",
    "\n",
    "All it is required to train on the FAUST_registration dataset for this demo is available for download at\n",
    "https://www.dropbox.com/s/aamd98nynkvbcop/EG16_tutorial.tar.bz2?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ICNN Toolbox\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/sosiris/TAU16_seminar.git\n",
    "```\n",
    "\n",
    "![](http://www.people.usi.ch/mascij/EG16_tutorial/shapenet_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is enabled with initial size: 70.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.sparse as Tsp\n",
    "\n",
    "import lasagne as L\n",
    "import lasagne.layers as LL\n",
    "import lasagne.objectives as LO\n",
    "import lasagne.nonlinearities as LN\n",
    "from lasagne.layers.normalization import batch_norm\n",
    "\n",
    "sys.path.append('..')\n",
    "from icnn import utils_lasagne, dataset, snapshotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train descs\n",
      "elapsed time 0.632000\n",
      "Loading test descs\n",
      "elapsed time 0.562000\n",
      "Loading train patches\n",
      "elapsed time 2.359000\n",
      "Loading test patches\n",
      "elapsed time 2.310000\n",
      "Loading train LB bases\n",
      "elapsed time 0.649000\n",
      "Loading test LB bases\n",
      "elapsed time 0.472000\n",
      "Loading train labels\n",
      "elapsed time 0.057000\n",
      "Loading test labels\n",
      "elapsed time 0.060000\n"
     ]
    }
   ],
   "source": [
    "reload(dataset)\n",
    "base_path = './dataset/FAUST_registrations/data/diam=200/'\n",
    "\n",
    "ds = dataset.ClassificationDatasetPatchesMinimal(\n",
    "    'FAUST_registrations_train.txt', 'FAUST_registrations_test.txt',\n",
    "    os.path.join(base_path, 'descs', 'shot'),\n",
    "    os.path.join(base_path, 'patch_aniso', 'alpha=100_nangles=016_ntvals=005_tmin=6.000_tmax=24.000_thresh=99.900_norm=L1'), \n",
    "    None, \n",
    "    os.path.join(base_path, 'lbo'),\n",
    "    os.path.join(base_path, 'labels'),\n",
    "    epoch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16)\n",
      "(None, 32)\n",
      "(None, 64)\n",
      "(None, 128)\n",
      "(None, 6890)\n",
      "(None, 6890)\n"
     ]
    }
   ],
   "source": [
    "reload(utils_lasagne)\n",
    "nin = 544\n",
    "nclasses = 6890\n",
    "l2_weight = 1e-5\n",
    "ref_lbo = T.constant(ds.train_lbo[0])\n",
    "\n",
    "def get_model(inp, patch_op, lb_op):\n",
    "    print(LL.get_output_shape(inp))\n",
    "    icnn = batch_norm(utils_lasagne.GCNNLayer([inp, patch_op], 16, nrings=5, nrays=16))\n",
    "    print(LL.get_output_shape(icnn))\n",
    "    icnn = batch_norm(utils_lasagne.GCNNLayer([icnn, patch_op], 32, nrings=5, nrays=16))\n",
    "    print(LL.get_output_shape(icnn))\n",
    "    icnn = batch_norm(utils_lasagne.GCNNLayer([icnn, patch_op], 20, nrings=5, nrays=16))\n",
    "    print(LL.get_output_shape(icnn))\n",
    "    # TODO: add functional mapping computation and application (maybe instead of the dense layer?)\n",
    "    ffn = utils_lasagne.FMAPLayer([icnn, lb_op], ref_lbo=ref_lbo, neigen=20)\n",
    "    ffn =  batch_norm(LL.DenseLayer(ffn, 128, nonlinearity=LN.rectify))\n",
    "    print(LL.get_output_shape(ffn))\n",
    "    ffn = LL.DenseLayer(ffn, nclasses, nonlinearity=utils_lasagne.log_softmax)\n",
    "\n",
    "    print(LL.get_output_shape(ffn))\n",
    "    return ffn\n",
    "\n",
    "inp = LL.InputLayer(shape=(None, nin))\n",
    "patch_op = LL.InputLayer(input_var=Tsp.csc_fmatrix('patch_op'), shape=(None, None))\n",
    "lb_op = LL.InputLayer(input_var=T.matrix('lb_op'), shape=(None, None))\n",
    "\n",
    "ffn = get_model(inp, patch_op, lb_op)\n",
    "\n",
    "# L.layers.get_output -> theano variable representing network\n",
    "output = LL.get_output(ffn)\n",
    "print(LL.get_output_shape(ffn))\n",
    "pred = LL.get_output(ffn, deterministic=True)  # in case we use dropout\n",
    "\n",
    "# target theano variable indicatind the index a vertex should be mapped to wrt the latent space\n",
    "target = T.ivector('idxs')\n",
    "\n",
    "# to work with logit predictions, better behaved numerically\n",
    "cla = utils_lasagne.categorical_crossentropy_logdomain(output, target, nclasses).mean()\n",
    "acc = LO.categorical_accuracy(pred, target).mean()\n",
    "\n",
    "# a bit of regularization is commonly used\n",
    "regL2 = L.regularization.regularize_network_params(ffn, L.regularization.l2)\n",
    "\n",
    "\n",
    "cost = cla + l2_weight * regL2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define the update rule, how to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = LL.get_all_params(ffn, trainable=True)\n",
    "grads = T.grad(cost, params)\n",
    "# computes the L2 norm of the gradient to better inspect training\n",
    "grads_norm = T.nlinalg.norm(T.concatenate([g.flatten() for g in grads]), 2)\n",
    "\n",
    "# Adam turned out to be a very good choice for correspondence\n",
    "updates = L.updates.adam(grads, params, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "funcs = dict()\n",
    "funcs['train'] = theano.function([inp.input_var, patch_op.input_var, lb_op.input_var, target],\n",
    "                                 [cost, cla, l2_weight * regL2, grads_norm, acc], updates=updates,\n",
    "                                 on_unused_input='warn')\n",
    "funcs['acc_loss'] = theano.function([inp.input_var, patch_op.input_var, lb_op.input_var, target],\n",
    "                                    [acc, cost], on_unused_input='warn')\n",
    "funcs['predict'] = theano.function([inp.input_var, patch_op.input_var, lb_op.input_var],\n",
    "                                   [pred], on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training (a bit simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 000][trn] cost  8.719976 (cla 8.7119, reg 0.0080), |grad| = 6.197805, acc = 0.01974 % (254.63sec)\n",
      "           [tst] cost  9.228011, acc = 0.01451 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_train_params!\n",
      "ERROR:root:[KVP] Overwriting group best_test_params!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001][trn] cost  8.671412 (cla 8.6611, reg 0.0103), |grad| = 9.366352, acc = 0.01771 % (256.89sec)\n",
      "           [tst] cost  8.598345, acc = 0.01451 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_train_params!\n",
      "ERROR:root:[KVP] Overwriting group best_test_params!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 002][trn] cost  8.552391 (cla 8.5402, reg 0.0122), |grad| = 0.550655, acc = 0.02380 % (255.76sec)\n",
      "           [tst] cost  8.589051, acc = 0.01451 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_train_params!\n",
      "ERROR:root:[KVP] Overwriting group best_test_params!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 003][trn] cost  8.512502 (cla 8.4984, reg 0.0141), |grad| = 2.043639, acc = 0.02525 % (253.92sec)\n",
      "           [tst] cost  8.614318, acc = 0.02903 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_train_params!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 004][trn] cost  8.483652 (cla 8.4673, reg 0.0164), |grad| = 0.698160, acc = 0.03164 % (254.12sec)\n",
      "           [tst] cost  8.578880, acc = 0.03387 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_train_params!\n",
      "ERROR:root:[KVP] Overwriting group best_test_params!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 005][trn] cost  8.478245 (cla 8.4598, reg 0.0185), |grad| = 0.982590, acc = 0.02177 % (253.49sec)\n",
      "           [tst] cost  8.638432, acc = 0.02177 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_train_params!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 006][trn] cost  8.441512 (cla 8.4211, reg 0.0204), |grad| = 4.029118, acc = 0.03135 % (253.86sec)\n",
      "           [tst] cost  8.588840, acc = 0.01935 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_train_params!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 007][trn] cost  8.448655 (cla 8.4258, reg 0.0228), |grad| = 1.586036, acc = 0.02845 % (254.72sec)\n",
      "           [tst] cost  8.555907, acc = 0.02419 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_test_params!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 008][trn] cost  8.450781 (cla 8.4255, reg 0.0253), |grad| = 3.718126, acc = 0.02032 % (255.86sec)\n",
      "           [tst] cost  8.651540, acc = 0.04838 %\n",
      "[Epoch 009][trn] cost  8.443307 (cla 8.4165, reg 0.0269), |grad| = 2.215768, acc = 0.03048 % (256.26sec)\n",
      "           [tst] cost  8.508147, acc = 0.02661 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_test_params!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 010][trn] cost  8.418008 (cla 8.3892, reg 0.0288), |grad| = 0.865371, acc = 0.04093 % (255.03sec)\n",
      "           [tst] cost  8.515579, acc = 0.02903 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_train_params!\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "eval_freq = 1\n",
    "\n",
    "start_time = time.time()\n",
    "best_trn = 1e5\n",
    "best_tst = 1e5\n",
    "\n",
    "kvs = snapshotter.Snapshotter('demo_training.snap')\n",
    "\n",
    "for it_count in xrange(n_epochs):\n",
    "    tic = time.time()\n",
    "    b_l, b_c, b_s, b_r, b_g, b_a = [], [], [], [], [], []\n",
    "    for x_ in ds.train_iter():\n",
    "        tmp = funcs['train'](*x_)\n",
    "\n",
    "        # do some book keeping (store stuff for training curves etc)\n",
    "        b_l.append(tmp[0])\n",
    "        b_c.append(tmp[1])\n",
    "        b_r.append(tmp[2])\n",
    "        b_g.append(tmp[3])\n",
    "        b_a.append(tmp[4])\n",
    "    epoch_cost = np.asarray([np.mean(b_l), np.mean(b_c), np.mean(b_r), np.mean(b_g), np.mean(b_a)])\n",
    "    print(('[Epoch %03i][trn] cost %9.6f (cla %6.4f, reg %6.4f), |grad| = %.06f, acc = %7.5f %% (%.2fsec)') %\n",
    "                 (it_count, epoch_cost[0], epoch_cost[1], epoch_cost[2], epoch_cost[3], epoch_cost[4] * 100, \n",
    "                  time.time() - tic))\n",
    "\n",
    "    if np.isnan(epoch_cost[0]):\n",
    "        print(\"NaN in the loss function...let's stop here\")\n",
    "        break\n",
    "\n",
    "    if (it_count % eval_freq) == 0:\n",
    "        v_c, v_a = [], []\n",
    "        for x_ in ds.test_iter():\n",
    "            tmp = funcs['acc_loss'](*x_)\n",
    "            v_a.append(tmp[0])\n",
    "            v_c.append(tmp[1])\n",
    "        test_cost = [np.mean(v_c), np.mean(v_a)]\n",
    "        print(('           [tst] cost %9.6f, acc = %7.5f %%') % (test_cost[0], test_cost[1] * 100))\n",
    "\n",
    "        if epoch_cost[0] < best_trn:\n",
    "            kvs.store('best_train_params', [it_count, LL.get_all_param_values(ffn)])\n",
    "            best_trn = epoch_cost[0]\n",
    "        if test_cost[0] < best_tst:\n",
    "            kvs.store('best_test_params', [it_count, LL.get_all_param_values(ffn)])\n",
    "            best_tst = test_cost[0]\n",
    "print(\"...done training %f\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test phase\n",
    "Now that the model is train it is enough to take the fwd function and apply it to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rewrite = True\n",
    "\n",
    "out_path = './dumps/' \n",
    "kvs.load('best_test_params')\n",
    "\n",
    "print \"Saving output to: %s\" % out_path\n",
    "\n",
    "if not os.path.isdir(out_path) or rewrite==True:\n",
    "    try:\n",
    "        os.makedirs(out_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    a = []\n",
    "    for i,d in enumerate(ds.test_iter()):\n",
    "        fname = os.path.join(out_path, \"%s\" % ds.test_fnames[i])\n",
    "        print fname,\n",
    "        tmp = funcs['predict'](d[0], d[1])[0]\n",
    "        a.append(np.mean(np.argmax(tmp, axis=1).flatten() == d[2].flatten()))\n",
    "        scipy.io.savemat(fname, {'desc': tmp})\n",
    "        print \", Acc: %7.5f %%\" % (a[-1] * 100.0)\n",
    "    print \"\\nAverage accuracy across all shapes: %7.5f %%\" % (np.mean(a) * 100.0)\n",
    "else:\n",
    "    print \"Model predictions already produced.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](http://www.people.usi.ch/mascij/EG16_tutorial/shapenet_corr.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasagne",
   "language": "python",
   "name": "lasagne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
