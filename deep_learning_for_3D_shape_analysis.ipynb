{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Prerequisites\n",
    "Install Theano and Lasagne using the following commands:\n",
    "\n",
    "```bash\n",
    "pip install -r https://raw.githubusercontent.com/Lasagne/Lasagne/master/requirements.txt\n",
    "pip install https://github.com/Lasagne/Lasagne/archive/master.zip\n",
    "```\n",
    "\n",
    "Working in a virtual environment is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data preparation\n",
    "\n",
    "Current code allows to generate geodesic patches from a collection of shapes represented as triangular meshes.\n",
    "To get started with the pre-processing:\n",
    "```\n",
    "git clone https://github.com/jonathanmasci/ShapeNet_data_preparation_toolbox.git\n",
    "```\n",
    "\n",
    "The usual processing pipeline is show in ```run_forrest_run.m```. \n",
    "We will soon update this preparation stage, so perhaps better to start with our pre-computed dataset, and stay tuned! :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepared data\n",
    "\n",
    "All it is required to train on the FAUST_registration dataset for this demo is available for download at\n",
    "https://www.dropbox.com/s/aamd98nynkvbcop/EG16_tutorial.tar.bz2?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ICNN Toolbox\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/sosiris/TAU16_seminar.git\n",
    "```\n",
    "\n",
    "![](http://www.people.usi.ch/mascij/EG16_tutorial/shapenet_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.sparse as Tsp\n",
    "\n",
    "import lasagne as L\n",
    "import lasagne.layers as LL\n",
    "import lasagne.objectives as LO\n",
    "import lasagne.nonlinearities as LN\n",
    "from lasagne.layers.normalization import batch_norm\n",
    "\n",
    "sys.path.append('..')\n",
    "from icnn import utils_lasagne, dataset, snapshotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train descs\n",
      "elapsed time 8.207000\n",
      "Loading test descs\n",
      "elapsed time 1.846000\n",
      "Loading train patches\n",
      "elapsed time 32.311000\n",
      "Loading test patches\n",
      "elapsed time 7.828000\n",
      "Loading train LB bases\n",
      "elapsed time 4.954000\n",
      "Loading test LB bases\n",
      "elapsed time 1.168000\n",
      "Loading train labels\n",
      "elapsed time 0.477000\n",
      "Loading test labels\n",
      "elapsed time 0.162000\n"
     ]
    }
   ],
   "source": [
    "reload(dataset)\n",
    "base_path = './dataset/FAUST_registrations/data/diam=200/'\n",
    "\n",
    "ds = dataset.ClassificationDatasetPatchesMinimal(\n",
    "    'FAUST_registrations_train.txt', 'FAUST_registrations_test.txt',\n",
    "    os.path.join(base_path, 'descs', 'shot'),\n",
    "    os.path.join(base_path, 'patch_aniso', 'alpha=100_nangles=016_ntvals=005_tmin=6.000_tmax=24.000_thresh=99.900_norm=L1'), \n",
    "    None, \n",
    "    os.path.join(base_path, 'lbo'),\n",
    "    os.path.join(base_path, 'labels'),\n",
    "    epoch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 544)\n",
      "(None, 16)\n",
      "(None, 32)\n",
      "(None, 64)\n",
      "(None, 64)\n",
      "(None, 6890)\n",
      "(None, 6890)\n"
     ]
    }
   ],
   "source": [
    "reload(utils_lasagne)\n",
    "nin = 544\n",
    "nclasses = 6890\n",
    "l2_weight = 1e-5\n",
    "c_weight = 1e-2\n",
    "ref_lbo = T.constant(ds.train_lbo[0])\n",
    "\n",
    "def get_model(inp, patch_op, lb_op):\n",
    "    print(LL.get_output_shape(inp))\n",
    "    icnn = batch_norm(utils_lasagne.GCNNLayer([inp, patch_op], 16, nrings=5, nrays=16))\n",
    "    print(LL.get_output_shape(icnn))\n",
    "    icnn = batch_norm(utils_lasagne.GCNNLayer([icnn, patch_op], 32, nrings=5, nrays=16))\n",
    "    print(LL.get_output_shape(icnn))\n",
    "    icnn = batch_norm(utils_lasagne.GCNNLayer([icnn, patch_op], 64, nrings=5, nrays=16))\n",
    "    print(LL.get_output_shape(icnn))\n",
    "    # TODO: add functional mapping computation and application (maybe instead of the dense layer?)\n",
    "    fmap = utils_lasagne.FMAPLayer([icnn, lb_op], neigen=30,\n",
    "                                 nonlinearity=LN.rectify)\n",
    "    print(LL.get_output_shape(fmap))\n",
    "    ffn = LL.DenseLayer(fmap, nclasses, nonlinearity=utils_lasagne.log_softmax)\n",
    "\n",
    "    print(LL.get_output_shape(ffn))\n",
    "    return ffn, fmap.C\n",
    "\n",
    "inp = LL.InputLayer(shape=(None, nin))\n",
    "patch_op = LL.InputLayer(input_var=Tsp.csc_fmatrix('patch_op'), shape=(None, None))\n",
    "lb_op = LL.InputLayer(input_var=T.matrix('lb_op'), shape=(None, None))\n",
    "\n",
    "ffn, C = get_model(inp, patch_op, lb_op)\n",
    "\n",
    "# L.layers.get_output -> theano variable representing network\n",
    "output = LL.get_output(ffn)\n",
    "print(LL.get_output_shape(ffn))\n",
    "pred = LL.get_output(ffn, deterministic=True)  # in case we use dropout\n",
    "\n",
    "# target theano variable indicatind the index a vertex should be mapped to wrt the latent space\n",
    "target = T.ivector('idxs')\n",
    "\n",
    "# to work with logit predictions, better behaved numerically\n",
    "cla = utils_lasagne.categorical_crossentropy_logdomain(output, target, nclasses).mean()\n",
    "acc = LO.categorical_accuracy(pred, target).mean()\n",
    "\n",
    "# a bit of regularization is commonly used\n",
    "regL2 = L.regularization.regularize_network_params(ffn, L.regularization.l2)\n",
    "\n",
    "# regularize fanuctional map to penalize non diagonal maps\n",
    "regC = L.regularization.apply_penalty(C, utils_lasagne.diag_penalty)\n",
    "\n",
    "cost = cla + l2_weight * regL2 + c_weight * regC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define the update rule, how to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = LL.get_all_params(ffn, trainable=True)\n",
    "grads = T.grad(cost, params)\n",
    "# computes the L2 norm of the gradient to better inspect training\n",
    "grads_norm = T.nlinalg.norm(T.concatenate([g.flatten() for g in grads]), 2)\n",
    "\n",
    "# Adam turned out to be a very good choice for correspondence\n",
    "updates = L.updates.adam(grads, params, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "funcs = dict()\n",
    "funcs['train'] = theano.function([inp.input_var, patch_op.input_var, lb_op.input_var, target],\n",
    "                                 [cost, cla, l2_weight * regL2, grads_norm, acc], updates=updates,\n",
    "                                 on_unused_input='warn')\n",
    "funcs['acc_loss'] = theano.function([inp.input_var, patch_op.input_var, lb_op.input_var, target],\n",
    "                                    [acc, cost], on_unused_input='warn')\n",
    "funcs['predict'] = theano.function([inp.input_var, patch_op.input_var, lb_op.input_var],\n",
    "                                   [pred], on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training (a bit simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 000][trn] cost  8.319470 (cla 8.3040, reg 0.0060), |grad| = 0.137901, acc = 0.11001 % (319.09sec)\n",
      "           [tst] cost  7.825659, acc = 0.19376 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_train_params!\n",
      "ERROR:root:[KVP] Overwriting group best_test_params!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001][trn] cost  7.480322 (cla 7.4541, reg 0.0167), |grad| = 0.274470, acc = 0.30392 % (261.87sec)\n",
      "           [tst] cost  7.205690, acc = 0.54354 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_train_params!\n",
      "ERROR:root:[KVP] Overwriting group best_test_params!\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "eval_freq = 1\n",
    "\n",
    "start_time = time.time()\n",
    "best_trn = 1e5\n",
    "best_tst = 1e5\n",
    "\n",
    "kvs = snapshotter.Snapshotter('demo_training.snap')\n",
    "\n",
    "for it_count in xrange(n_epochs):\n",
    "    tic = time.time()\n",
    "    b_l, b_c, b_s, b_r, b_g, b_a = [], [], [], [], [], []\n",
    "    for x_ in ds.train_iter():\n",
    "        tmp = funcs['train'](*x_)\n",
    "\n",
    "        # do some book keeping (store stuff for training curves etc)\n",
    "        b_l.append(tmp[0])\n",
    "        b_c.append(tmp[1])\n",
    "        b_r.append(tmp[2])\n",
    "        b_g.append(tmp[3])\n",
    "        b_a.append(tmp[4])\n",
    "    epoch_cost = np.asarray([np.mean(b_l), np.mean(b_c), np.mean(b_r), np.mean(b_g), np.mean(b_a)])\n",
    "    print(('[Epoch %03i][trn] cost %9.6f (cla %6.4f, reg %6.4f), |grad| = %.06f, acc = %7.5f %% (%.2fsec)') %\n",
    "                 (it_count, epoch_cost[0], epoch_cost[1], epoch_cost[2], epoch_cost[3], epoch_cost[4] * 100, \n",
    "                  time.time() - tic))\n",
    "\n",
    "    if np.isnan(epoch_cost[0]):\n",
    "        print(\"NaN in the loss function...let's stop here\")\n",
    "        break\n",
    "\n",
    "    if (it_count % eval_freq) == 0:\n",
    "        v_c, v_a = [], []\n",
    "        for x_ in ds.test_iter():\n",
    "            tmp = funcs['acc_loss'](*x_)\n",
    "            v_a.append(tmp[0])\n",
    "            v_c.append(tmp[1])\n",
    "        test_cost = [np.mean(v_c), np.mean(v_a)]\n",
    "        print(('           [tst] cost %9.6f, acc = %7.5f %%') % (test_cost[0], test_cost[1] * 100))\n",
    "\n",
    "        if epoch_cost[0] < best_trn:\n",
    "            kvs.store('best_train_params', [it_count, LL.get_all_param_values(ffn)])\n",
    "            best_trn = epoch_cost[0]\n",
    "        if test_cost[0] < best_tst:\n",
    "            kvs.store('best_test_params', [it_count, LL.get_all_param_values(ffn)])\n",
    "            best_tst = test_cost[0]\n",
    "print(\"...done training %f\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test phase\n",
    "Now that the model is train it is enough to take the fwd function and apply it to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving output to: ./dumps/\n",
      "./dumps/tr_reg_080.mat"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Missing required input: lb_op",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e836e350a649>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_fnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavemat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'desc'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\itay.boneh\\AppData\\Local\\Continuum\\Miniconda3\\envs\\lasagne\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m                     raise TypeError(\"Missing required input: %s\" %\n\u001b[0;32m    866\u001b[0m                                     getattr(self.inv_finder[c], 'variable',\n\u001b[1;32m--> 867\u001b[1;33m                                             self.inv_finder[c]))\n\u001b[0m\u001b[0;32m    868\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprovided\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mrestore_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Missing required input: lb_op"
     ]
    }
   ],
   "source": [
    "rewrite = True\n",
    "\n",
    "out_path = './dumps/' \n",
    "kvs.load('best_test_params')\n",
    "\n",
    "print \"Saving output to: %s\" % out_path\n",
    "\n",
    "if not os.path.isdir(out_path) or rewrite==True:\n",
    "    try:\n",
    "        os.makedirs(out_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    a = []\n",
    "    for i,d in enumerate(ds.test_iter()):\n",
    "        fname = os.path.join(out_path, \"%s\" % ds.test_fnames[i])\n",
    "        print fname,\n",
    "        tmp = funcs['predict'](d[0], d[1], d[2])[0]\n",
    "        a.append(np.mean(np.argmax(tmp, axis=1).flatten() == d[3].flatten()))\n",
    "        scipy.io.savemat(fname, {'desc': tmp})\n",
    "        print \", Acc: %7.5f %%\" % (a[-1] * 100.0)\n",
    "    print \"\\nAverage accuracy across all shapes: %7.5f %%\" % (np.mean(a) * 100.0)\n",
    "else:\n",
    "    print \"Model predictions already produced.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](http://www.people.usi.ch/mascij/EG16_tutorial/shapenet_corr.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasagne",
   "language": "python",
   "name": "lasagne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
